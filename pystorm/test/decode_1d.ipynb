{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pystorm.hal import HAL, data_utils\n",
    "from pystorm.PyDriver import bddriver as bd\n",
    "from pystorm.hal.net_builder import NetBuilder\n",
    "from pystorm.hal.run_control import RunControl\n",
    "from pystorm.hal.calibrator import Calibrator, PoolSpec\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "# making a Y-by-X pool of D dims located at (LY, LX)\n",
    "\n",
    "Y, X = (32, 32)\n",
    "LY, LX = (0, 0)\n",
    "\n",
    "N = X * Y\n",
    "D = 1 # has to be 1 for this\n",
    "\n",
    "SY = Y // 2\n",
    "SX = X // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hal = HAL()\n",
    "net_builder = NetBuilder(hal)\n",
    "cal = Calibrator(hal)\n",
    "\n",
    "opt_ps_in = PoolSpec(YX=(Y,X), loc_yx=(LY, LX), D=1)\n",
    "DAC_vals = {\n",
    "        'DAC_SOMA_REF': 1024,\n",
    "        'DAC_DIFF_G': 1024,\n",
    "        'DAC_DIFF_R': 1024}\n",
    "\n",
    "opt_ps_out, opt_dacs, opt_encs, opt_offsets, std_encs, std_offsets, dbg = \\\n",
    "    cal.optimize_yield(opt_ps_in, dacs=DAC_vals, \n",
    "                       bias_twiddle_policy='greedy_flat', offset_source='calibration_db', validate=True,\n",
    "                       get_encs_kwargs=dict(bin_time=2, discard_time=.4, num_sample_angles=3))\n",
    "\n",
    "print(opt_dacs['DAC_DIFF_G'])\n",
    "print(opt_dacs['DAC_DIFF_R'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_encs, before_offsets = dbg['before']\n",
    "exp_encs, exp_offsets = dbg['expected']\n",
    "\n",
    "opt_good = Calibrator.get_good_mask(opt_encs, opt_offsets)\n",
    "exp_good = Calibrator.get_good_mask(exp_encs, exp_offsets)\n",
    "\n",
    "print('good exp:', np.sum(exp_good))\n",
    "print('good ver:', np.sum(opt_good))\n",
    "\n",
    "\n",
    "fs = (10, 10)\n",
    "xylim = (0, 800, -800, 1500)\n",
    "\n",
    "Calibrator.plot_neuron_yield_cone(exp_encs, exp_offsets, exp_good,\n",
    "                                 (before_encs, before_offsets, opt_ps_out.biases),\n",
    "                                  title='expected',\n",
    "                                  figsize=fs,\n",
    "                                  xylim=xylim)\n",
    "\n",
    "Calibrator.plot_neuron_yield_cone(opt_encs, opt_offsets, exp_good,\n",
    "                                 (before_encs, before_offsets, opt_ps_out.biases),\n",
    "                                  title='actual',\n",
    "                                  figsize=fs,\n",
    "                                  xylim=xylim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_val_samples = 200\n",
    "val_pts = np.linspace(-1, 1, N_val_samples).reshape((N_val_samples, 1))\n",
    "    \n",
    "val_rmse, val_meas_A, val_est_A = cal.validate_est_encs(opt_encs, opt_offsets, opt_ps_out, val_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try training on estimated tuning curves\n",
    "sqrt_num_sets = 4\n",
    "fig, ax = plt.subplots(sqrt_num_sets, sqrt_num_sets, figsize=(15, 15))\n",
    "for y in range(sqrt_num_sets):\n",
    "    for x in range(sqrt_num_sets):\n",
    "        imin = (y * sqrt_num_sets + x) * N // sqrt_num_sets**2\n",
    "        imax = imin + N // sqrt_num_sets**2\n",
    "        \n",
    "        ax[y, x].set_prop_cycle(None)\n",
    "        ax[y, x].plot(val_pts, val_est_A[:, imin:imax])\n",
    "        ax[y, x].set_prop_cycle(None)\n",
    "        ax[y, x].plot(val_pts, val_meas_A[:, imin:imax], '.-')\n",
    "        \n",
    "        #ax[y, x].axis((-1, 1, 0, 1000))\n",
    "        \n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(15, 6))\n",
    "diff = np.abs(val_est_A - val_meas_A)\n",
    "diff[np.isnan(diff)] = 0\n",
    "im = ax[0].imshow(diff, aspect='auto')\n",
    "divider = make_axes_locatable(ax[0])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "plt.colorbar(im, cax=cax)\n",
    "\n",
    "std_off = std_offsets.reshape((1, len(std_offsets)))\n",
    "std_off[:, np.isnan(opt_offsets)] = 0\n",
    "im = ax[1].imshow(std_off, aspect='auto') \n",
    "divider = make_axes_locatable(ax[1])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "plt.colorbar(im, cax=cax)\n",
    "\n",
    "std_enc = std_encs.reshape((1, len(std_encs)))\n",
    "std_enc[:, np.isnan(opt_offsets)] = 0\n",
    "im = ax[2].imshow(std_enc, aspect='auto') \n",
    "divider = make_axes_locatable(ax[2])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "plt.colorbar(im, cax=cax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toss out big error tuning curves\n",
    "\n",
    "diff = np.abs(val_est_A - val_meas_A)\n",
    "diff[np.isnan(diff)] = 0\n",
    "\n",
    "plt.figure()\n",
    "valid_means = np.sqrt(np.mean(diff**2, axis=0))\n",
    "plt.hist(valid_means)\n",
    "\n",
    "mean_rmse = np.mean(valid_means)\n",
    "print(mean_rmse)\n",
    "\n",
    "thr = 4\n",
    "big_err = valid_means > thr * mean_rmse\n",
    "plt.axvline(thr * mean_rmse)\n",
    "\n",
    "print(np.sum(big_err))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxpy import Variable, Problem, sum_squares, norm, Minimize\n",
    "\n",
    "def run_cvx_opt(A, y, lam, kappa):\n",
    "    \n",
    "    SCALE = 1000\n",
    "    Asc = A / SCALE\n",
    "    ysc = y / SCALE\n",
    "    \n",
    "    d = Variable((N, 1))\n",
    "    print((Asc * d).shape)\n",
    "    print(ysc.shape)\n",
    "    \n",
    "    loss = sum_squares(Asc * d - ysc)\n",
    "\n",
    "    cvx_prob = Problem(Minimize(loss + sum_squares(d) * lam + norm(d, 1) * kappa), [-1 <= d, d <= 1])\n",
    "    \n",
    "    #cvx_prob = Problem(Minimize(loss))\n",
    "    #cvx_prob = Problem(Minimize(loss + sum_squares(d) * lam))\n",
    "    #cvx_prob = Problem(Minimize(loss + sum_squares(d) * lam), [-1 <= d, d <= 1])\n",
    "    #cvx_prob = Problem(Minimize(loss + sum_squares(d) * lam + norm(d, 1) * kappa))\n",
    "    #cvx_prob = Problem(Minimize(loss + sum_squares(d) * lam + norm(d, 1) * kappa), [0 <= d, d <= 1])\n",
    "\n",
    "    cvx_prob.solve()\n",
    "\n",
    "    if cvx_prob.status == \"failed\":\n",
    "        print(\"solver status:\", cvx_prob.status)\n",
    "        d = None\n",
    "    else:\n",
    "        if cvx_prob.status != \"optimal\":\n",
    "            print(\"solver status:\", cvx_prob.status)\n",
    "            \n",
    "        dstar = d.value\n",
    "\n",
    "        print(dstar.shape)\n",
    "        d = dstar.reshape(N, 1)\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = .01\n",
    "kappa = .01\n",
    "train_frac = .7\n",
    "fout = 1000\n",
    "\n",
    "def yfn(x_pts):\n",
    "    return fout * (np.sin(4*np.pi * x_pts) + 1)/2\n",
    "\n",
    "\n",
    "N_sample = 200\n",
    "x_pts = np.linspace(-1, 1, N_sample).reshape((N_sample, 1))\n",
    "A_est = np.maximum(0, np.dot(x_pts, opt_encs.T) + opt_offsets)\n",
    "\n",
    "#N_sample = N_val_samples\n",
    "#x_pts = val_pts\n",
    "#A_est = val_meas_A\n",
    "\n",
    "print(N_sample)\n",
    "print(x_pts.shape)\n",
    "print(A_est.shape)\n",
    "\n",
    "y = yfn(x_pts)\n",
    "\n",
    "perm = np.random.permutation(np.arange(N_sample))\n",
    "train_idxs = np.sort(perm[:int(N_sample * train_frac)])\n",
    "test_idxs = np.sort(perm[int(N_sample * train_frac):])\n",
    "\n",
    "A_est_val = A_est.copy()\n",
    "A_est_val[np.isnan(A_est)] = 0\n",
    "A_est_val[:, big_err] = 0 # throw out big errors\n",
    "\n",
    "A_train = A_est_val[train_idxs, :]\n",
    "A_test = A_est_val[test_idxs, :]\n",
    "y_train = y[train_idxs, :]\n",
    "y_test = y[test_idxs, :]\n",
    "x_train = x_pts[train_idxs, :]\n",
    "x_test = x_pts[test_idxs, :]\n",
    "\n",
    "d = run_cvx_opt(A_train, y_train, lam, kappa)\n",
    "\n",
    "yhat_train = np.dot(A_train, d)\n",
    "yhat_test = np.dot(A_test, d)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_train, y_train)\n",
    "plt.plot(x_train, yhat_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_test, y_test)\n",
    "plt.plot(x_test, yhat_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(d[np.abs(d) > 1/128], bins=20)\n",
    "plt.title('weight hist')\n",
    "\n",
    "one = np.abs(d) > (1 - 1/128)\n",
    "nonzero = np.abs(d) > 1 / 128\n",
    "nonone = np.abs(d) < (1 - 1/128)\n",
    "\n",
    "print((np.sum(nonzero & nonone)) / N)\n",
    "print(np.sum(one) / (np.sum(nonzero & nonone) + np.sum(one)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do real validation, run sweep\n",
    "N_val_pts = 41\n",
    "sample_pts = np.linspace(-1, 1, N_val_pts)\n",
    "y_sample = yfn(sample_pts)\n",
    "\n",
    "#######################\n",
    "\n",
    "import time\n",
    "\n",
    "HOLD_TIME = 1 # seconds\n",
    "LPF_DISCARD_TIME = HOLD_TIME / 2 # seconds\n",
    "\n",
    "# set up run controller to help us do sweeps\n",
    "nb = NetBuilder(hal)\n",
    "d_fixed = d.copy()\n",
    "d_fixed[d > 1] = 1\n",
    "d_fixed[d < -1] = -1\n",
    "net = nb.create_single_pool_net_from_spec(opt_ps_out, decoders=d_fixed.T)\n",
    "pool = net.get_pools()[0]\n",
    "inp = net.get_inputs()[0]\n",
    "out = net.get_outputs()[0]\n",
    "\n",
    "hal.map(net)\n",
    "\n",
    "for dac, value in opt_dacs.items():\n",
    "    hal.set_DAC_value(dac, value)\n",
    "# let the DACs settle down\n",
    "time.sleep(.5)\n",
    "\n",
    "run = RunControl(hal, net) \n",
    "\n",
    "tnow = hal.get_time()\n",
    "times = np.arange(sample_pts.shape[0]) * HOLD_TIME * 1e9 + tnow + .1e9 \n",
    "times_w_end = np.arange(sample_pts.shape[0] + 1) * HOLD_TIME * 1e9 + tnow + .1e9 \n",
    "start_time = times[0]\n",
    "end_time = times[-1] + HOLD_TIME * 1e9\n",
    "sample_freqs = sample_pts * opt_ps_out.fmax\n",
    "\n",
    "input_vals = {inp: (times, sample_freqs.reshape((len(sample_freqs), 1)))}\n",
    "\n",
    "spikes_and_bin_times, _ = run.run_input_sweep(input_vals, get_raw_spikes=False, get_outputs=True, \n",
    "                                start_time=start_time, end_time=end_time, rel_time=False)\n",
    "print(\"done sweeping\")\n",
    "spikes, spike_bin_times = spikes_and_bin_times\n",
    "\n",
    "discard_frac = LPF_DISCARD_TIME / HOLD_TIME\n",
    "meas_A = data_utils.bins_to_rates(spikes[out], spike_bin_times, times_w_end, init_discard_frac=discard_frac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(sample_pts, y_sample)\n",
    "plt.plot(sample_pts, meas_A)\n",
    "rmse = np.sqrt(np.mean(((meas_A.flatten() - y_sample.flatten())**2)))\n",
    "plt.title('rmse = ' + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
