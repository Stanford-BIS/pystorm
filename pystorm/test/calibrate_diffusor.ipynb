{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick and Dirty Diffusor Calibration\n",
    "\n",
    "calibrates $gDT$ where $T$ is the tap point matrix, $D$ is the diffusor kernels (in this case, with no edges cut) and $g$ is the set of neuron gains.\n",
    "\n",
    "This is meant to be used to drop into the existing numerical simulations of diffusor spread.\n",
    "\n",
    "To make this more practical (working just a single pool), you would need to collect different sets with different diffusor cut conditions. To be complete, for each tap point location, you'd have kernels for (num DAC spreads) * {no cuts nearby, cut above, cut right, cut left, cut down, cut above+right, cut above+left, etc.}. For broad spreads, you'd have to add cuts 2 away, 3 away, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pystorm.hal import HAL\n",
    "from pystorm.PyDriver import bddriver as bd\n",
    "from pystorm.hal.net_builder import NetBuilder\n",
    "from pystorm.hal.calibrator import Calibrator, PoolSpec\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full chip\n",
    "Y = X = 64\n",
    "LY = LX = 0\n",
    "SY = Y // 2\n",
    "SX = X // 2\n",
    "D = 1\n",
    "\n",
    "DACS = dict(DAC_DIFF_G = 1024,\n",
    "            DAC_DIFF_R = 600,\n",
    "            DAC_SOMA_REF = 1024,\n",
    "            DAC_SOMA_OFFSET = 2)\n",
    "\n",
    "# need O(grid_space**2 samples)\n",
    "# how many synapses to leave off between active synapses\n",
    "SYN_GRID_SPACE = 8\n",
    "assert(SYN_GRID_SPACE % 2 == 0) # use an even number to keep #taps even\n",
    "\n",
    "KY = KX = SYN_GRID_SPACE * 2\n",
    "\n",
    "# estimate_encoders for 1D takes 9 samples/trial 2 times, 1 s per sample\n",
    "trial_extra = 33\n",
    "print('runtime estimate:', (9 * 1 * 2 + trial_extra) * SYN_GRID_SPACE**2 / 60, 'minutes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hal = HAL()\n",
    "cal = Calibrator(hal)\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "all_encs = {}\n",
    "#for y_grid_idx in range(1):\n",
    "#    for x_grid_idx in range(1):\n",
    "for y_grid_idx in range(SYN_GRID_SPACE):\n",
    "    for x_grid_idx in range(SYN_GRID_SPACE):\n",
    "        print(\"RUNNING Y:\", y_grid_idx, \"X:\", x_grid_idx)\n",
    "        print(\"=======================\")\n",
    "        print((time.time() - t0) / 60, 'minutes elapsed')\n",
    "        \n",
    "        syn_TPM = np.zeros((SY, SX))\n",
    "        syn_TPM[y_grid_idx::SYN_GRID_SPACE, x_grid_idx::SYN_GRID_SPACE] = 1\n",
    "        TPM = NetBuilder.syn_taps_to_nrn_taps(syn_TPM.reshape((SY, SX, 1)))\n",
    "\n",
    "        # use bias 3, want lots of spiking\n",
    "        ps = PoolSpec(YX=(Y,X), loc_yx=(LY, LX), D=D, TPM=TPM, biases=3)\n",
    "        ps.fmax = cal.optimize_fmax(ps, safety_margin=.95)\n",
    "        \n",
    "        # estimate encoders\n",
    "        encs, offs, std_encs, std_offs, _, _ = \\\n",
    "            cal.get_encoders_and_offsets(ps, dacs=DACS, num_sample_angles=3, bin_time=2, num_bootstraps=20)\n",
    "            \n",
    "        all_encs[(y_grid_idx, x_grid_idx)] = dict(ps=ps, encs=encs, std_encs=std_encs)\n",
    "        \n",
    "import pickle\n",
    "pck_fname = 'calibrate_diffusor_' + str(DACS['DAC_DIFF_G']) + '_' + str(DACS['DAC_DIFF_R']) + '.pck'\n",
    "pickle.dump(all_encs, open(pck_fname, 'wb'))\n",
    "\n",
    "print((time.time() - t0) / 60, 'minutes elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "DAC_DIFF_G = DACS['DAC_DIFF_G']\n",
    "DAC_DIFF_R = DACS['DAC_DIFF_R']\n",
    "#DAC_DIFF_G = 1024\n",
    "#DAC_DIFF_R = 600\n",
    "pck_fname = 'calibrate_diffusor_' + str(DAC_DIFF_G) + '_' + str(DAC_DIFF_R) + '.pck'\n",
    "all_encs = pickle.load(open(pck_fname, 'rb'))\n",
    "\n",
    "for (y_grid_idx, x_grid_idx), enc_dict in all_encs.items():\n",
    "    encs = enc_dict['encs']\n",
    "    std_encs = enc_dict['std_encs']\n",
    "    ps = enc_dict['ps']\n",
    "    \n",
    "    # plot raw responses and errors\n",
    "    ps_for_plot = ps.copy()\n",
    "    ps_for_plot.TPM = np.hstack((ps.TPM, ps.TPM))\n",
    "    Calibrator.plot_encs_yx(np.hstack((encs, std_encs)), ps_for_plot, figheight=4)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotlog=False\n",
    "\n",
    "kernels = {}\n",
    "Ksums = []\n",
    "for (y_grid_idx, x_grid_idx), enc_dict in all_encs.items():\n",
    "    encs = enc_dict['encs']\n",
    "    std_encs = enc_dict['std_encs']\n",
    "    \n",
    "    # extract kernels\n",
    "    yx_encs = np.zeros((Y + 2*SYN_GRID_SPACE, X + 2*SYN_GRID_SPACE))\n",
    "    yx_std_encs = np.zeros_like(yx_encs)\n",
    "    \n",
    "    # zero-padded outside\n",
    "    yx_encs[SYN_GRID_SPACE:-SYN_GRID_SPACE, SYN_GRID_SPACE:-SYN_GRID_SPACE] = encs.reshape((Y, X))\n",
    "    yx_std_encs[SYN_GRID_SPACE:-SYN_GRID_SPACE, SYN_GRID_SPACE:-SYN_GRID_SPACE] = std_encs.reshape((Y, X))\n",
    "    \n",
    "    # nrn idxs\n",
    "    for y_center_idx in range(y_grid_idx*2, Y, SYN_GRID_SPACE*2):\n",
    "        for x_center_idx in range(x_grid_idx*2, X, SYN_GRID_SPACE*2):\n",
    "            if (y_center_idx // 2) % 2 == 0:\n",
    "                xshift = 0\n",
    "            else:\n",
    "                xshift = 1\n",
    "\n",
    "            ymin = SYN_GRID_SPACE + y_center_idx - SYN_GRID_SPACE\n",
    "            xmin = SYN_GRID_SPACE + x_center_idx - SYN_GRID_SPACE + xshift\n",
    "            ymax = SYN_GRID_SPACE + y_center_idx + SYN_GRID_SPACE + 1\n",
    "            xmax = SYN_GRID_SPACE + x_center_idx + SYN_GRID_SPACE + 1 + xshift\n",
    "            \n",
    "            K = yx_encs[ymin:ymax, xmin:xmax]\n",
    "            Kpos = K.copy()\n",
    "            #Kpos[Kpos < 0] = 0\n",
    "            Kpos[np.isnan(Kpos)] = 0\n",
    "            \n",
    "            Kerr = yx_std_encs[ymin:ymax, xmin:xmax]\n",
    "            \n",
    "            # cancel out sketchy measurements\n",
    "            # 95% confidence interval bigger than half measured value\n",
    "            big_err = Kerr * 2 > Kpos * .5\n",
    "            \n",
    "            Kpos[big_err] = 0\n",
    "            \n",
    "            Ksums.append(np.sum(Kpos))\n",
    "            \n",
    "            kernels[y_center_idx // 2, x_center_idx // 2] = dict(K=Kpos, Kerr=Kerr)\n",
    "            \n",
    "print(np.mean(Ksums))\n",
    "            \n",
    "all_encs_flat = np.abs(all_encs[0,0]['encs'].flatten())\n",
    "all_encs_flat[np.isnan(all_encs_flat)] = 0\n",
    "vmin = 0\n",
    "vmax = np.sort(all_encs_flat)[int(.99 * len(all_encs_flat))]\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "pmin = 8\n",
    "pmax = 16\n",
    "PYX = pmax - pmin\n",
    "\n",
    "fig, ax = plt.subplots(2*PYX, PYX, figsize=(15, 30))\n",
    "\n",
    "for (sy, sx), k_dict in kernels.items():\n",
    "    if sy >= pmin and sy < pmax and sx >= pmin and sx < pmax:\n",
    "        spy = sy - pmin\n",
    "        spx = sx - pmin\n",
    "        \n",
    "        Kpos = k_dict['K']\n",
    "        Kerr = k_dict['Kerr']\n",
    "        \n",
    "        if plotlog:\n",
    "            im = ax[spy, spx].imshow(np.log(Kpos + 1), vmin=np.log(vmin + 1), vmax=np.log(vmax + 1))\n",
    "            plt.colorbar(im)\n",
    "            \n",
    "        else:\n",
    "            #im = ax[spy, spx].imshow(Kpos, vmin=vmin, vmax=vmax)\n",
    "            this_ax = ax[2*spy, spx]\n",
    "            im = this_ax.imshow(Kpos, vmin=vmin, vmax=vmax)\n",
    "            divider = make_axes_locatable(this_ax)\n",
    "            cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "            this_ax.axis('off')\n",
    "            plt.colorbar(im, cax=cax)\n",
    "            \n",
    "            this_ax = ax[2*spy + 1, spx]\n",
    "            im = this_ax.imshow(2 * Kerr, cmap='gray_r') # ~95% confidence\n",
    "            divider = make_axes_locatable(this_ax)\n",
    "            cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "            this_ax.axis('off')\n",
    "            plt.colorbar(im, cax=cax)\n",
    "plt.tight_layout(w_pad=.02, h_pad=.02, pad=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.stdout.write('\\a')\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
