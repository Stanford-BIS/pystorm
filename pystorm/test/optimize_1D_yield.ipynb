{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the number of 'good' neurons in a 1D pool\n",
    "\n",
    "Calibrator does a lot of this now with `optimize_for_yield()`, but the process was developed in this notebook.\n",
    "\n",
    "We'll compare results near the end. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pystorm.hal import HAL\n",
    "from pystorm.PyDriver import bddriver as bd\n",
    "from pystorm.hal.net_builder import NetBuilder\n",
    "from pystorm.hal.calibrator import Calibrator, PoolSpec\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "# making a Y-by-X pool of D dims located at (LY, LX)\n",
    "\n",
    "Y, X = (16, 16)\n",
    "LY, LX = (16, 0)\n",
    "\n",
    "N = X * Y\n",
    "D = 1 # has to be 1 for this\n",
    "\n",
    "SY = Y // 2\n",
    "SX = X // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hal = HAL()\n",
    "net_builder = NetBuilder(hal)\n",
    "cal = Calibrator(hal)\n",
    "\n",
    "ps = PoolSpec(YX=(Y,X), loc_yx=(LY, LX), D=1)\n",
    "\n",
    "nrn_tap_matrix, syn_tap_matrix = cal.create_optimized_yx_taps(ps)\n",
    "ps.TPM = nrn_tap_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine if syn_tap_matrix is right/left or up/down +1/-1 \n",
    "# so I know if I'm cutting it in two correctly\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(syn_tap_matrix.reshape(SY, SX))\n",
    "plt.colorbar()\n",
    "plt.title('tap point assignments\\ncorner coordinates:\\nCCW from top-left: (0, 0), (SY, 0), (SY, SX), (0, SX)')\n",
    "\n",
    "print(syn_tap_matrix[0, 0])\n",
    "print(syn_tap_matrix[SY-1, 0])\n",
    "print(syn_tap_matrix[0, SX-1])\n",
    "print(syn_tap_matrix[SY-1, SX-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the Network object, call yield optimization function\n",
    "def run_network(ps_orig, diff_G=1024, diff_R=1024, cut='none', biases=0):\n",
    "    ps = ps_orig.copy()\n",
    "    ps.biases = biases\n",
    "    \n",
    "    DAC_vals = {\n",
    "        'DAC_SOMA_REF': 1024,\n",
    "        'DAC_DIFF_G': diff_G,\n",
    "        'DAC_DIFF_R': diff_R}\n",
    "\n",
    "    # net is now mapped, try slicing the diffusor\n",
    "    if cut == 'line':\n",
    "        ps.diffusor_cuts_yx = NetBuilder.get_diff_cuts_to_break_pool_in_half(ps.Y, ps.X)\n",
    "\n",
    "    # determine fmax\n",
    "    ps.fmax = cal.optimize_fmax(ps)\n",
    "\n",
    "    # estimate encoders and offsets\n",
    "    encoders, offsets, _, _ = cal.get_encoders_and_offsets(ps, dacs=DAC_vals,\n",
    "                                                           num_sample_angles=3,\n",
    "                                                           solver='scipy_opt')\n",
    "    \n",
    "    return encoders, offsets, ps, DAC_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# do exhaustive twiddle val search, like Terry does\n",
    "# TODO come back and try with the calibration\n",
    "\n",
    "import pickle\n",
    "pck_fname = 'raw_offsets.pck'\n",
    "REDO_SWEEP = False\n",
    "\n",
    "if REDO_SWEEP:\n",
    "    raw_offsets = np.zeros((7, N))\n",
    "    for bias_idx, bias in enumerate([-3, -2, -1, 0, 1, 2, 3]):\n",
    "        encoders, offsets, _, _ = run_network(ps, diff_G=1024, diff_R=1024, cut='line', biases=bias)\n",
    "        raw_offsets[bias_idx, :] = offsets\n",
    "    pickle.dump(raw_offsets, open(pck_fname, 'wb'))\n",
    "else:\n",
    "    raw_offsets = pickle.load(open(pck_fname, 'rb'))\n",
    "    \n",
    "# make it like the soma_bias_twiddle calibration, relative to bias twiddle 0\n",
    "all_offsets = raw_offsets.copy()\n",
    "orig_offsets_at_3 = raw_offsets[6, :]\n",
    "orig_offsets_at_0 = raw_offsets[3, :]\n",
    "    \n",
    "# subtract out 0 bias\n",
    "for bias_idx, bias in enumerate([-3, -2, -1, 0, 1, 2, 3]):\n",
    "    all_offsets[bias_idx, :] -= orig_offsets_at_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot resulting offsets\n",
    "plt.figure()\n",
    "plt.plot(raw_offsets)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_offsets)\n",
    "\n",
    "# estimate slope of each neurons sampled twiddle levels\n",
    "# the mismatch of each level is correlated\n",
    "# this is a better way of estimating unsampled bias levels than what \n",
    "# the calibration does\n",
    "\n",
    "all_offsets_est = Calibrator.extrapolate_bias_twiddles(all_offsets)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_offsets_est)\n",
    "print('hi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize_twiddles_once(ps, cut, diff_G, diff_R):\n",
    "\n",
    "    def run_curr_network(biases):\n",
    "        return run_network(ps, diff_G=diff_G, diff_R=diff_R, cut=cut, biases=biases)\n",
    "\n",
    "    encoders, offsets, _, _ = run_curr_network(3)\n",
    "    offsets_at_3 = offsets\n",
    "\n",
    "    bias_settings, new_offsets, good, bin_counts, dbg = \\\n",
    "        Calibrator.optimize_bias_twiddles(encoders, offsets_at_3, all_offsets_est, policy='center')\n",
    "\n",
    "    fs = (15, 15)\n",
    "    xylim = (0, 800, -800, 1500)\n",
    "    Calibrator.plot_neuron_yield_cone(encoders, new_offsets, good,\n",
    "                                     (encoders, offsets, bias_settings),\n",
    "                                      title='expected',\n",
    "                                      figsize=fs,\n",
    "                                      xylim=xylim)\n",
    "\n",
    "    encoders_opt, offsets_opt, ps_opt, dacs_opt = run_curr_network(bias_settings)\n",
    "\n",
    "    Calibrator.plot_neuron_yield_cone(encoders_opt, offsets_opt, good,\n",
    "                                     (encoders, offsets, bias_settings),\n",
    "                                      title='trick opt vs trick',\n",
    "                                      figsize=fs,\n",
    "                                      xylim=xylim)\n",
    "\n",
    "    good_orig = np.sum(Calibrator.get_good_mask(encoders, offsets))\n",
    "    good_exp = np.sum(Calibrator.get_good_mask(encoders, new_offsets))\n",
    "    good_ver = np.sum(Calibrator.get_good_mask(encoders_opt, offsets_opt))\n",
    "    print('good orig:', good_orig)\n",
    "    print('good exp:', good_exp)\n",
    "    print('good ver:', good_ver)\n",
    "    \n",
    "    return encoders_opt, offsets_opt, good_ver, ps_opt, dacs_opt\n",
    "        \n",
    "def do_validation_exp(encoders_opt, offsets_opt, ps, dacs):\n",
    "    ps.fmax = cal.optimize_fmax(ps)\n",
    "    NUM_VAL_SAMPLES = 20\n",
    "    val_pts = np.linspace(-1, 1, NUM_VAL_SAMPLES).reshape((NUM_VAL_SAMPLES, 1))\n",
    "    rmse, meas_A, est_A = cal.validate_est_encs(encoders_opt, offsets_opt, ps, val_pts, dacs=dacs)\n",
    "    return val_pts, meas_A\n",
    "\n",
    "def plot_validation_exp(encoders_opt, offsets_opt, val_pts, meas_A, lines_per_plot=None):\n",
    "\n",
    "    clean_encs = encoders_opt.copy()\n",
    "    unest = np.isnan(offsets_opt)\n",
    "    clean_encs[unest, :] = 0\n",
    "    clean_offsets = offsets_opt.copy()\n",
    "    clean_offsets[unest] = 0\n",
    "\n",
    "    est_A = np.maximum(0, np.dot(val_pts, clean_encs.T) + clean_offsets)\n",
    "\n",
    "    if lines_per_plot is not None:\n",
    "        n_neurons = meas_A.shape[1]\n",
    "        plot_nrn_idxs = np.random.permutation(np.arange(n_neurons))[:lines_per_plot]\n",
    "        print(plot_nrn_idxs)\n",
    "        meas_A_plot = meas_A[:, plot_nrn_idxs]\n",
    "        est_A_plot = est_A[:, plot_nrn_idxs]\n",
    "    else:\n",
    "        meas_A_plot = meas_A\n",
    "        est_A_plot = est_A\n",
    "        \n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.gca().set_prop_cycle(None)\n",
    "    plt.plot(val_pts, meas_A_plot, '.-')\n",
    "    plt.gca().set_prop_cycle(None)\n",
    "    plt.plot(val_pts, est_A_plot, '-')\n",
    "    plt.axis([-1, 1, 0, 1500]) \n",
    "    plt.title('estimated vs measured tuning curves')\n",
    "    \n",
    "    tuned_on = encoders_opt[:, 0].flatten() > 0\n",
    "    meas_A_on = meas_A[:, tuned_on]\n",
    "    meas_A_off = meas_A[:, ~tuned_on]\n",
    "    est_A_on = est_A[:, tuned_on]\n",
    "    est_A_off = est_A[:, ~tuned_on]\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 2, figsize=(15, 15))\n",
    "    ax[0, 0].plot(val_pts, meas_A_off)\n",
    "    ax[0, 1].plot(val_pts, meas_A_on)\n",
    "    ax[0, 0].axis([-1, 1, 0, 1500]) \n",
    "    ax[0, 1].axis([-1, 1, 0, 1500]) \n",
    "    ax[1, 0].plot(val_pts, est_A_off)\n",
    "    ax[1, 1].plot(val_pts, est_A_on)\n",
    "    ax[1, 0].axis([-1, 1, 0, 1500]) \n",
    "    ax[1, 1].axis([-1, 1, 0, 1500]) \n",
    "    plt.suptitle('measured (above) and estimated (below) tuning curves, N = 256, .5s of raw spikes data/pt')\n",
    "    \n",
    "    plt.figure(figsize=(15,12))\n",
    "    plt.plot(val_pts, est_A)\n",
    "    plt.axis([-1, 1, 0, 1500]) \n",
    "    plt.title('estimated tuning curves')\n",
    "\n",
    "    plt.figure()\n",
    "    is_est = ~unest\n",
    "    gains = Calibrator.get_gains(encoders_opt[is_est, :])\n",
    "    intercepts = -offsets_opt[is_est] / gains\n",
    "    plt.hist(intercepts, bins=np.linspace(-2, 2, 21))\n",
    "    plt.title('intercept distribution')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "encs, offs, good_ct, ps_opt, dacs_opt = optimize_twiddles_once(ps, 'line', 1024, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val_pts, meas_A = do_validation_exp(encs, offs, ps_opt, dacs_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_validation_exp(encs, offs, val_pts, meas_A, lines_per_plot=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to Calibrator.optimize_yield()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opt_ps_in = PoolSpec(YX=(Y,X), loc_yx=(LY, LX), D=2)\n",
    "DAC_vals = {\n",
    "        'DAC_SOMA_REF': 1024,\n",
    "        'DAC_DIFF_G': 1024,\n",
    "        'DAC_DIFF_R': 1024}\n",
    "\n",
    "opt_ps_out, opt_encs, opt_offsets, dbg = \\\n",
    "    cal.optimize_yield(opt_ps_in, dacs=DAC_vals, bias_twiddle_policy='center', offset_source='calibration_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_encs, before_offsets = dbg['before']\n",
    "exp_encs, exp_offsets = dbg['expected']\n",
    "\n",
    "opt_good = Calibrator.get_good_mask(opt_encs, opt_offsets)\n",
    "exp_good = Calibrator.get_good_mask(exp_encs, exp_offsets)\n",
    "\n",
    "print('good exp:', np.sum(exp_good))\n",
    "print('good ver:', np.sum(opt_good))\n",
    "\n",
    "\n",
    "fs = (10, 10)\n",
    "xylim = (0, 800, -800, 1500)\n",
    "\n",
    "Calibrator.plot_neuron_yield_cone(exp_encs, exp_offsets, exp_good,\n",
    "                                 (before_encs, before_offsets, opt_ps_out.biases),\n",
    "                                  title='expected',\n",
    "                                  figsize=fs,\n",
    "                                  xylim=xylim)\n",
    "\n",
    "Calibrator.plot_neuron_yield_cone(opt_encs, opt_offsets, exp_good,\n",
    "                                 (before_encs, before_offsets, opt_ps_out.biases),\n",
    "                                  title='actual',\n",
    "                                  figsize=fs,\n",
    "                                  xylim=xylim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusor Hyperparameter Sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sweep diffusor spread, measuring for yield\n",
    "def run_diffusor_sweep(ps, cut, diff_Gs, diff_Rs):\n",
    "    encs = []\n",
    "    offs = []\n",
    "    good_cts = []\n",
    "    for diff_G, diff_R in zip(diff_Gs, diff_Rs):\n",
    "        optimize_twiddles_once(ps, cut, diff_G, diff_R)\n",
    "        \n",
    "        encs.append(encoders_opt)\n",
    "        offs.append(encoders_opt)\n",
    "        good_cts.append(good_ver)\n",
    "        \n",
    "    return encs, offs, good_cts, net_opt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diff_Rs = [500, 1024, 1024]\n",
    "diff_Gs = [1024, 1024, 500]\n",
    "cut = 'line'\n",
    "run_diffusor_sweep(ps, cut, diff_Gs, diff_Rs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diff_Rs = [1024, 500, 100]\n",
    "diff_Gs = [1024]*len(diff_Rs)\n",
    "cut = 'none'\n",
    "run_diffusor_sweep(ps, cut, diff_Gs, diff_Rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# see how much bad_syns helps\n",
    "\n",
    "default_syn_tap_matrix = NetBuilder.create_default_yx_taps(Y // 2, X // 2, D)\n",
    "default_nrn_tap_matrix = NetBuilder.syn_taps_to_nrn_taps(default_syn_tap_matrix)\n",
    "NetBuilder.make_taps_even(default_nrn_tap_matrix)\n",
    "\n",
    "ps_bad_taps = ps.copy()\n",
    "\n",
    "diff_Rs = [1024]\n",
    "diff_Gs = [1024]\n",
    "\n",
    "cut = 'line'\n",
    "run_diffusor_sweep(ps_bad_taps, cut, diff_Gs, diff_Rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
