{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nengo.solvers import LstsqL2\n",
    "from nengo_extras.plot_spikes import plot_spikes\n",
    "\n",
    "import pystorm\n",
    "from pystorm.hal import HAL\n",
    "from pystorm.hal.net_builder import NetBuilder\n",
    "from pystorm.hal.run_control import RunControl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set parameters for network\n",
    "#   number of neurons\n",
    "# create the network\n",
    "#   set tap points - this can be encapsulated and improved later\n",
    "\n",
    "# what should I set the gain and bias bits to?\n",
    "# \n",
    "X = 16\n",
    "Y = 16\n",
    "NNEURON = X*Y\n",
    "DIM = 1\n",
    "FMAX = 1000\n",
    "\n",
    "DOWNSTREAM_NS = 10000\n",
    "\n",
    "hal = pystorm.hal.HAL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net_builder = NetBuilder(hal)\n",
    "\n",
    "bad_syn = hal.get_calibration(\"synapse\", \"high_bias_magnitude\")\n",
    "SX = X // 2\n",
    "SY = Y // 2\n",
    "tap_matrix_syn = net_builder.create_default_yx_taps(SY, SX, DIM, bad_syn)\n",
    "tap_matrix = net_builder.syn_taps_to_nrn_taps(tap_matrix_syn)\n",
    "np.savetxt(\"tap_matrix.txt\", tap_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gain_divs = np.loadtxt(\"gain_divisors.txt\", dtype=int)\n",
    "biases = np.loadtxt(\"biases.txt\", dtype=int)\n",
    "net = net_builder.create_single_pool_net(\n",
    "    Y, X, tap_matrix, biases=biases, gain_divs=gain_divs, decoders=np.zeros((1, Y*X)))\n",
    "run_control = RunControl(hal, net)\n",
    "\n",
    "hal.map(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_size = 0.5 # seconds\n",
    "bin_size_ns = int(bin_size*1E9)\n",
    "hal.set_time_resolution(DOWNSTREAM_NS, bin_size_ns)\n",
    "\n",
    "total_train_points = 11\n",
    "offset_time = 1.\n",
    "offset_time_ns = int(offset_time*1E9)\n",
    "\n",
    "train_rates = np.zeros((total_train_points+1, 1))\n",
    "train_rates[:total_train_points,0] = FMAX * np.linspace(-1, 1, total_train_points)\n",
    "train_rates[-1, 0] = train_rates[-2, 0]\n",
    "\n",
    "train_time_ns = np.arange(total_train_points+1)*bin_size_ns+offset_time_ns\n",
    "train_time_ns += hal.get_time()\n",
    "\n",
    "input_vals = {net.input:(train_time_ns, train_rates)}\n",
    "\n",
    "outputs_data, spike_data = run_control.run_input_sweep(\n",
    "    input_vals, get_raw_spikes=True, get_outputs=False)\n",
    "spikes, bin_times = spike_data\n",
    "\n",
    "spikes = spikes[net.pool]\n",
    "rates = spikes/bin_size\n",
    "train_rates = train_rates[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tuning(inputs, rates):\n",
    "    n_bins, n_neurons = rates.shape\n",
    "    nsq = int(np.sqrt(n_neurons))\n",
    "    half_sq = nsq//2\n",
    "    for idx in range(nsq):\n",
    "        start_l = 2*idx*half_sq\n",
    "        start_r = start_l + half_sq\n",
    "        plt.plot(inputs, rates[:, start_l:start_l+half_sq], 'r')\n",
    "        plt.plot(inputs, rates[:, start_r:start_r+half_sq], 'b')\n",
    "plot_tuning(train_rates, rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit decoders\n",
    "\n",
    "target_function = train_rates + FMAX\n",
    "solver = LstsqL2(reg=0.1)\n",
    "print(rates.shape)\n",
    "print(target_function.shape)\n",
    "decoders, info = solver(rates, target_function)\n",
    "rmse = info['rmses']\n",
    "print(rmse)\n",
    "train_decode = np.dot(rates, decoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_idx = np.searchsorted(train_rates[:, 0], 0)\n",
    "rates_0 = rates[z_idx]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_rates, target_function)\n",
    "plt.plot(train_rates, train_decode)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(decoders[rates_0>0])\n",
    "#TODO: collect testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.decoder_conn.reassign_weights(decoders.T)\n",
    "hal.remap_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run tests\n",
    "#  deliver an input of 0\n",
    "time_resolution_ns = 100000\n",
    "hal.set_time_resolution(DOWNSTREAM_NS, time_resolution_ns)\n",
    "\n",
    "offset_time = 0.3\n",
    "offset_time_ns = int(offset_time*1E9)\n",
    "\n",
    "test_time = 1\n",
    "test_time_ns = int(test_time*1E9)\n",
    "\n",
    "test_rates = np.zeros((2, 1))\n",
    "test_times = np.arange(2)*test_time_ns + offset_time_ns\n",
    "now_ns = hal.get_time()\n",
    "test_times += now_ns\n",
    "\n",
    "input_vals = {net.input:(test_times, test_rates)}\n",
    "\n",
    "output_data, spike_data = run_control.run_input_sweep(\n",
    "    input_vals, get_raw_spikes=True, get_outputs=True)\n",
    "\n",
    "outputs, output_bin_times = output_data\n",
    "spikes, spike_bin_times = spike_data\n",
    "outputs = outputs[net.output][:, 0]\n",
    "spikes = spikes[net.pool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_bin_times = np.arange(10)\n",
    "# outputs = np.arange(10*2).reshape((10, 2))\n",
    "# spike_bin_times = np.arange(10)[1:-2]\n",
    "# spikes = np.arange(10*2).reshape((10, 2))[1:-2]\n",
    "# print(output_bin_times)\n",
    "# print(spike_bin_times)\n",
    "# print(outputs)\n",
    "# print(spikes)\n",
    "\n",
    "# clip arrays to same time region\n",
    "# start of array\n",
    "if output_bin_times[0] < spike_bin_times[0]:\n",
    "    idx = np.searchsorted(output_bin_times, spike_bin_times[0])\n",
    "    print(\"clipping {:d} elements from output data start to align with spike data start\".format(idx))\n",
    "    output_bin_times = output_bin_times[idx:]\n",
    "    outputs = outputs[idx:]\n",
    "elif spike_bin_times[0] < output_bin_times[0]:\n",
    "    idx = np.searchsorted(spike_bin_times, output_bin_times[0])\n",
    "    print(\"clipping {:d} elements from spike data start to align with output data start\".format(idx))\n",
    "    spike_bin_times = spike_bin_times[idx:]\n",
    "    spikes = spikes[idx:]\n",
    "# end of array\n",
    "if output_bin_times[-1] > spike_bin_times[-1]:\n",
    "    # clip output_bin_times\n",
    "    idx = np.searchsorted(output_bin_times, spike_bin_times[-1], 'right')\n",
    "    print(\"clipping {:d} elements from output data end to align with spike data end\".format(len(output_bin_times)-idx))\n",
    "    output_bin_times = output_bin_times[:idx]\n",
    "    outputs = outputs[:idx]\n",
    "elif spike_bin_times[-1] > output_bin_times[-1]:\n",
    "    # clip spike_bin_times\n",
    "    idx = np.searchsorted(spike_bin_times, output_bin_times[-1], 'right')\n",
    "    print(\"clipping {:d} elements from spike data end to align with output data start\".format(len(spike_bin_times)-idx))\n",
    "    spike_bin_times = spike_bin_times[:idx]\n",
    "    spikes = spikes[:idx]\n",
    "# print(output_bin_times)\n",
    "# print(spike_bin_times)\n",
    "# print(outputs)\n",
    "# print(spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process output data\n",
    "output_times = (output_bin_times - now_ns - offset_time_ns) / 1E9\n",
    "\n",
    "bins_gt0 = np.sum(outputs>0)\n",
    "total_outputs = np.sum(outputs)\n",
    "bins_1 = np.sum(outputs==1)\n",
    "bins_2 = np.sum(outputs==2)\n",
    "bins_gt2 = np.sum(outputs>2)\n",
    "bin_vals_gt2 = np.unique(outputs[outputs>2])\n",
    "print(\"Collected {:d} non-zero output bins. Sum(outputs) {:d}\".format(bins_gt0, total_outputs))\n",
    "print(\"Bin stats:1-spike bins: {:d}, 2-spike bins: {:d}, >2-spike bins: {:d} (bin values {})\".format(\n",
    "    bins_1, bins_2, bins_gt2, bin_vals_gt2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process spike data\n",
    "bins_gt0 = np.sum(spikes>0)\n",
    "total_spikes = np.sum(spikes)\n",
    "bins_1 = np.sum(spikes==1)\n",
    "bins_2 = np.sum(spikes==2)\n",
    "bins_3 = np.sum(spikes==3)\n",
    "bins_gt3 = np.sum(spikes>3)\n",
    "bin_vals_gt3 = np.unique(spikes[spikes>3])\n",
    "print(\"Collected {:d} non-zero spike bins. Sum(spikes) {:d}\".format(bins_gt0, total_spikes))\n",
    "print(\"Bin stats:1-spike bins: {:d}, 2-spike bins: {:d}, 3-spike bins: {:d}, >3-spike bins: {:d} (bin values {})\".format(\n",
    "    bins_1, bins_2, bins_3, bins_gt3, bin_vals_gt3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a raster of spikes and outputs\n",
    "to_raster = np.zeros((spikes.shape[0], spikes.shape[1]+1), dtype=int)\n",
    "to_raster[:, 1:] = spikes\n",
    "to_raster[:, 0] = outputs\n",
    "to_raster[to_raster>1] = 1\n",
    "plt.subplots(figsize=(16, 12))\n",
    "plot_spikes(output_times, to_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpf(signal, tau, dt):\n",
    "    \"\"\"Low pass filters a 1D timeseries\"\"\"\n",
    "    ret = np.zeros(signal.shape)\n",
    "    decay = np.expm1(-dt/tau)+1\n",
    "    increment = -np.expm1(-dt/tau)/dt\n",
    "    ret += increment*signal\n",
    "    for idx in range(1, len(signal)):\n",
    "        ret[idx] += ret[idx-1]*decay\n",
    "    return ret\n",
    "\n",
    "sample_rate = 10000\n",
    "dt = float(time_resolution_ns)*1E-9\n",
    "tau = 0.01\n",
    "\n",
    "valid_outputs = outputs.copy()\n",
    "valid_outputs[outputs>10] = 0\n",
    "filtered_outputs = lpf(valid_outputs, tau, dt)\n",
    "\n",
    "decoded_spikes = spikes*decoders.flatten()\n",
    "filtered_decoded_spikes = lpf(decoded_spikes, tau, dt)\n",
    "decode = np.sum(filtered_decoded_spikes, axis=1) \n",
    "\n",
    "mean = np.mean(filtered_outputs[output_times>5*tau])\n",
    "var = np.var(filtered_outputs[output_times>5*tau])\n",
    "print(mean/np.sqrt(var))\n",
    "\n",
    "plt.subplots(figsize=(10,4))\n",
    "plt.plot(output_times, filtered_outputs, label=\"filtered accumulator output\")\n",
    "plt.plot(output_times, decode, label=\"filtered, decode-weighted, raw spikes\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_outputs = np.zeros((len(output_times), 3))\n",
    "scratch_outputs[outputs[:,0]==1, 0] = 1\n",
    "scratch_outputs[outputs[:,0]==2, 1] = 1\n",
    "scratch_outputs[outputs[:,0]>2, 2] = 1\n",
    "# plot_spikes(output_times, scratch_outputs)\n",
    "plt.subplots(figsize=(8,6))\n",
    "plt.plot(output_times, scratch_outputs)\n",
    "plt.xlim(0, 1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### open ideas\n",
    "\n",
    "- compare to all weights positive and equal\n",
    "- check for poissonness of superposed spike trains\n",
    "- sweep decoder magnitude"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
